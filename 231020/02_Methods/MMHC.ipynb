{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be8b39c-a0b4-4e93-a528-22f52d6c7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pgmpy.estimators import MmhcEstimator\n",
    "from pgmpy.estimators import BDeuScore\n",
    "from pgmpy.estimators import HillClimbSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c3e0418c-06d7-4e0f-9215-edcc25e4da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Mitsu/Desktop/AISTATS/230930_MMHC/\")\n",
    "def input_data(filename, num_of_var):\n",
    "    tmp = pd.read_csv(\"sample_data_\"+str(num_of_var)+\"_\"+filename, sep=\",\", encoding=\"utf-8\")\n",
    "    del tmp[\"Unnamed: 0\"]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "26c7114d-8168-4bc1-ad50-064780c5b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_(tmp):\n",
    "    if \"e\" in tmp:\n",
    "        var = tmp.split(\"e\")[1].split(\"(\")[0]\n",
    "        matrix = \"E\"\n",
    "    elif \"x\" in tmp:\n",
    "        if \"t-1\" in tmp:\n",
    "            var = tmp.split(\"x\")[1].split(\"(\")[0]\n",
    "            matrix = \"B1\"\n",
    "        elif \"t\" in tmp:\n",
    "            var = tmp.split(\"x\")[1].split(\"(\")[0]\n",
    "            matrix = \"B0\"\n",
    "    else:\n",
    "            pass\n",
    "    return var, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "440b1b5d-a05d-4403-98b5-0adde092fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Measurements(coeff_pred, coeff_truth):\n",
    "    TP,TN,FP,FN=0,0,0,0\n",
    "    for i in range(coeff_pred.shape[0]):\n",
    "        for j in range(coeff_pred.shape[1]):\n",
    "            if coeff_pred[i][j] == coeff_truth[i][j]:\n",
    "                if coeff_pred[i][j]==1.0:\n",
    "                    # print(\"True positive\", coeff_pred[i][j])\n",
    "                    TP += 1\n",
    "                elif coeff_pred[i][j]==0.0:\n",
    "                    # print(\"True negative\", coeff_pred[i][j])\n",
    "                    TN += 1\n",
    "            else:\n",
    "                if coeff_pred[i][j]==1.0:\n",
    "                    # print(\"False positive\", coeff_pred[i][j])\n",
    "                    FP += 1\n",
    "                elif coeff_pred[i][j]==0.0:\n",
    "                    # print(\"False negative\", coeff_pred[i][j])\n",
    "                    FN += 1\n",
    "\n",
    "    Accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    # Precision = TP / (TP + FP)\n",
    "    Recall = TP / (TP+FN)\n",
    "    F1 = TP / (TP + 1/2 * (FP + FN))\n",
    "    MyScore = 1 / ( 1 + (FP + FN) )\n",
    "    MyScore2 = (FP + FN)  / (TP + FP + FN + TN)\n",
    "    return Accuracy, Recall, F1, MyScore, MyScore2 # Precision, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cf88aad6-5ee8-4b54-9cd4-7d71e17afab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_var:  2\n",
      "Part 1) Skeleton:  [('x0(t)', 'e1(t)'), ('x1(t)', 'e0(t)'), ('x1(t)', 'x1(t-1)'), ('x0(t-1)', 'e0(t)'), ('e0(t)', 'e1(t)')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347baf9f2c274af4b03455259fd9751d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2) Model:     [('x1(t)', 'e0(t)'), ('x1(t-1)', 'x1(t)'), ('e0(t)', 'x0(t-1)'), ('e0(t)', 'e1(t)'), ('e1(t)', 'x0(t)')]\n",
      "107.60927210003138 sec.\n",
      "   Num_of_var  Accuracy  Recall   F1  Error rate  1/(1+FP+FN)        Time  \\\n",
      "0           2  0.583333     0.0  0.0    0.416667     0.166667  107.609272   \n",
      "\n",
      "                                        Coeff_Truth  \\\n",
      "0  [[0, 0], [0, 0], [0, 1], [0, 0], [1, 0], [0, 1]]   \n",
      "\n",
      "                            Coeff_result_probability  \n",
      "0  [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 1.0...  \n",
      "num_of_var:  3\n",
      "Part 1) Skeleton:  [('x0(t)', 'x0(t-1)'), ('x0(t)', 'e1(t)'), ('x1(t)', 'e2(t)'), ('x1(t)', 'e1(t)'), ('x2(t)', 'e2(t)'), ('x2(t)', 'x0(t-1)'), ('x2(t)', 'e1(t)'), ('x0(t-1)', 'x2(t-1)'), ('x0(t-1)', 'e2(t)'), ('x0(t-1)', 'x1(t-1)'), ('x1(t-1)', 'e0(t)'), ('x1(t-1)', 'e1(t)'), ('x2(t-1)', 'e2(t)'), ('e0(t)', 'e1(t)')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0fbe111b03468091d7cc9d0d6834fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2) Model:     [('x1(t)', 'e1(t)'), ('x1(t)', 'e2(t)'), ('x2(t-1)', 'x0(t-1)'), ('e0(t)', 'x1(t-1)'), ('e1(t)', 'x0(t)'), ('e1(t)', 'x2(t)'), ('e1(t)', 'e0(t)'), ('e2(t)', 'x2(t-1)')]\n",
      "1641.1262395000085 sec.\n",
      "   Num_of_var  Accuracy  Recall   F1  Error rate  1/(1+FP+FN)        Time  \\\n",
      "0           3  0.666667     0.0  0.0    0.333333          0.1  1641.12624   \n",
      "\n",
      "                                         Coeff_Truth  \\\n",
      "0  [[0, 1, 0], [0, 0, 1], [0, 0, 0], [1, 0, 0], [...   \n",
      "\n",
      "                            Coeff_result_probability  \n",
      "0  [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, ...  \n",
      "num_of_var:  4\n",
      "Part 1) Skeleton:  [('x0(t)', 'x1(t-1)'), ('x0(t)', 'x0(t-1)'), ('x0(t)', 'e1(t)'), ('x0(t)', 'x3(t)'), ('x1(t)', 'e3(t)'), ('x1(t)', 'e0(t)'), ('x2(t)', 'x0(t-1)'), ('x2(t)', 'e0(t)'), ('x3(t)', 'x0(t-1)'), ('x3(t)', 'e0(t)'), ('x3(t)', 'x3(t-1)'), ('x3(t)', 'e1(t)'), ('x0(t-1)', 'x2(t-1)'), ('x0(t-1)', 'e0(t)'), ('x0(t-1)', 'e1(t)'), ('x0(t-1)', 'e3(t)'), ('x1(t-1)', 'x3(t-1)'), ('x1(t-1)', 'x2(t-1)'), ('x2(t-1)', 'e3(t)'), ('x2(t-1)', 'x3(t-1)'), ('x2(t-1)', 'e0(t)'), ('e0(t)', 'e2(t)'), ('e0(t)', 'e3(t)'), ('e2(t)', 'e3(t)')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9eb74f0b644d73a68f594fe39b917f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2) Model:     [('x3(t)', 'e1(t)'), ('x3(t)', 'x0(t-1)'), ('x1(t-1)', 'x0(t)'), ('x1(t-1)', 'x3(t-1)'), ('x2(t-1)', 'e0(t)'), ('x2(t-1)', 'x1(t-1)'), ('e0(t)', 'e3(t)'), ('e0(t)', 'x3(t)'), ('e0(t)', 'x2(t)'), ('e3(t)', 'x1(t)'), ('e3(t)', 'e2(t)')]\n",
      "17334.65415810002 sec.\n",
      "   Num_of_var  Accuracy  Recall   F1  Error rate  1/(1+FP+FN)          Time  \\\n",
      "0           4  0.666667     0.0  0.0    0.333333     0.058824  17334.654158   \n",
      "\n",
      "                                         Coeff_Truth  \\\n",
      "0  [[0, 0, 1, 0], [0, 0, 1, 1], [0, 0, 0, 1], [0,...   \n",
      "\n",
      "                            Coeff_result_probability  \n",
      "0  [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...  \n",
      "num_of_var:  5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m time_sta \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     14\u001b[0m mmhc \u001b[38;5;241m=\u001b[39m MmhcEstimator(data)\n\u001b[1;32m---> 15\u001b[0m skeleton \u001b[38;5;241m=\u001b[39m mmhc\u001b[38;5;241m.\u001b[39mmmpc()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPart 1) Skeleton: \u001b[39m\u001b[38;5;124m\"\u001b[39m, skeleton\u001b[38;5;241m.\u001b[39medges())\n\u001b[0;32m     18\u001b[0m hc \u001b[38;5;241m=\u001b[39m HillClimbSearch(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sam_env\\Lib\\site-packages\\pgmpy\\estimators\\MmhcEstimator.py:189\u001b[0m, in \u001b[0;36mMmhcEstimator.mmpc\u001b[1;34m(self, significance_level)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Forward Phase\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     new_neighbor, new_neighbor_min_assoc \u001b[38;5;241m=\u001b[39m max_min_heuristic(\n\u001b[0;32m    190\u001b[0m         node, neighbors[node]\n\u001b[0;32m    191\u001b[0m     )\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_neighbor_min_assoc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    193\u001b[0m         neighbors[node]\u001b[38;5;241m.\u001b[39mappend(new_neighbor)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sam_env\\Lib\\site-packages\\pgmpy\\estimators\\MmhcEstimator.py:175\u001b[0m, in \u001b[0;36mMmhcEstimator.mmpc.<locals>.max_min_heuristic\u001b[1;34m(X, Zs)\u001b[0m\n\u001b[0;32m    172\u001b[0m best_Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(nodes) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(Zs \u001b[38;5;241m+\u001b[39m [X]):\n\u001b[1;32m--> 175\u001b[0m     min_assoc_val \u001b[38;5;241m=\u001b[39m min_assoc(X, Y, Zs)\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m min_assoc_val \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_min_assoc:\n\u001b[0;32m    177\u001b[0m         best_Y \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sam_env\\Lib\\site-packages\\pgmpy\\estimators\\MmhcEstimator.py:167\u001b[0m, in \u001b[0;36mMmhcEstimator.mmpc.<locals>.min_assoc\u001b[1;34m(X, Y, Zs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin_assoc\u001b[39m(X, Y, Zs):\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinimal association of X, Y given any subset of Zs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(assoc(X, Y, Zs_subset) \u001b[38;5;28;01mfor\u001b[39;00m Zs_subset \u001b[38;5;129;01min\u001b[39;00m powerset(Zs))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sam_env\\Lib\\site-packages\\pgmpy\\estimators\\MmhcEstimator.py:167\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin_assoc\u001b[39m(X, Y, Zs):\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinimal association of X, Y given any subset of Zs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(assoc(X, Y, Zs_subset) \u001b[38;5;28;01mfor\u001b[39;00m Zs_subset \u001b[38;5;129;01min\u001b[39;00m powerset(Zs))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sam_env\\Lib\\site-packages\\pgmpy\\estimators\\MmhcEstimator.py:163\u001b[0m, in \u001b[0;36mMmhcEstimator.mmpc.<locals>.assoc\u001b[1;34m(X, Y, Zs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massoc\u001b[39m(X, Y, Zs):\n\u001b[0;32m    160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Measure for (conditional) association between variables. Use negative\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    p-value of independence test.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m chi_square(X, Y, Zs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, boolean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sam_env\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:95\u001b[0m, in \u001b[0;36mchi_square\u001b[1;34m(X, Y, Z, data, boolean, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchi_square\u001b[39m(X, Y, Z, data, boolean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    Chi-square conditional independence test.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    Tests the null hypothesis that X is independent from Y given Zs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m power_divergence(\n\u001b[0;32m     96\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, Y\u001b[38;5;241m=\u001b[39mY, Z\u001b[38;5;241m=\u001b[39mZ, data\u001b[38;5;241m=\u001b[39mdata, boolean\u001b[38;5;241m=\u001b[39mboolean, lambda_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     97\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sam_env\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:550\u001b[0m, in \u001b[0;36mpower_divergence\u001b[1;34m(X, Y, Z, data, boolean, lambda_, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m z_state, df \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mgroupby(Z):\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m         c, _, d, _ \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mchi2_contingency(\n\u001b[0;32m    551\u001b[0m             df\u001b[38;5;241m.\u001b[39mgroupby([X, Y])\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39munstack(Y, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), lambda_\u001b[38;5;241m=\u001b[39mlambda_\n\u001b[0;32m    552\u001b[0m         )\n\u001b[0;32m    553\u001b[0m         chi \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m c\n\u001b[0;32m    554\u001b[0m         dof \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sam_env\\Lib\\site-packages\\scipy\\stats\\contingency.py:330\u001b[0m, in \u001b[0;36mchi2_contingency\u001b[1;34m(observed, correction, lambda_)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chi-square test of independence of variables in a contingency table.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mThis function computes the chi-square statistic and p-value for the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m0.64417725029295503\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    329\u001b[0m observed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(observed)\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(observed \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll values in `observed` must be nonnegative.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_of_var_list = [2,3,4]\n",
    "for num_of_var in num_of_var_list:\n",
    "    print(\"num_of_var: \",num_of_var)\n",
    "    train_gen = input_data(filename=\"train_gen.csv\", num_of_var=num_of_var)\n",
    "    train_dis = input_data(filename=\"train_dis.csv\", num_of_var=num_of_var)\n",
    "    test_gen = input_data(filename=\"test_gen.csv\", num_of_var=num_of_var)\n",
    "    test_dis = input_data(filename=\"test_dis.csv\", num_of_var=num_of_var)\n",
    "        \n",
    "    data = train_gen\n",
    "    # data = data[data.columns[0:num_of_var*2]]\n",
    "    \n",
    "    time_sta = time.perf_counter()\n",
    "    \n",
    "    mmhc = MmhcEstimator(data)\n",
    "    skeleton = mmhc.mmpc()\n",
    "    print(\"Part 1) Skeleton: \", skeleton.edges())\n",
    "    \n",
    "    hc = HillClimbSearch(data)\n",
    "    model = hc.estimate(tabu_length=10, white_list=skeleton.to_directed().edges(), scoring_method=BDeuScore(data))\n",
    "    print(\"Part 2) Model:    \", model.edges())\n",
    "    \n",
    "    time_end = time.perf_counter()\n",
    "    tim = time_end- time_sta\n",
    "    print(tim,\"sec.\")\n",
    "    ###################################################\n",
    "    \n",
    "    B0_pred = np.zeros([num_of_var, num_of_var])\n",
    "    B1_pred = np.zeros([num_of_var, num_of_var])\n",
    "    E_pred = np.zeros([num_of_var, num_of_var])\n",
    "    for edge in np.array(model.edges()):\n",
    "        edge_from = edge[0]\n",
    "        mat_from = mat_(edge_from)\n",
    "        edge_to = edge[1]\n",
    "        mat_to = mat_(edge_to)\n",
    "        if mat_from[1] == \"B0\":\n",
    "            if mat_to[1] == \"B0\":\n",
    "                B0_pred[int(mat_from[0]), int(mat_to[0])] = 1.0\n",
    "                \n",
    "        elif mat_from[1] == \"B1\":\n",
    "            if mat_to[1] == \"B0\":\n",
    "                B1_pred[int(mat_from[0]), int(mat_to[0])] = 1.0\n",
    "            \n",
    "        elif mat_from[1] == \"E\":\n",
    "            if mat_to[1] == \"B0\":\n",
    "                E_pred[int(mat_from[0]), int(mat_to[0])] = 1.0\n",
    "    \n",
    "    #############################################################\n",
    "    \n",
    "    tmp = pd.read_csv(\"sample_data_\"+str(num_of_var)+\".csv\", sep=\",\", encoding=\"utf-8\")\n",
    "    del tmp[\"Unnamed: 0\"]\n",
    "    B0 = np.array(tmp[0:num_of_var])\n",
    "    B1 = np.array(tmp[num_of_var : num_of_var * 2])\n",
    "    E = np.diag([1.0]*num_of_var)\n",
    "    coeff_truth = np.concatenate([B0, B1, E])\n",
    "    coeff_truth = np.where(abs(coeff_truth)>0.001, 1, 0)\n",
    "    coeff_pred = np.concatenate([B0_pred, B1_pred, E_pred])\n",
    "    Accuracy, Recall, F1, MyScore, MyScore2 = Measurements(coeff_pred, coeff_truth)\n",
    "    df = pd.DataFrame({\n",
    "        \"Num_of_var\": [num_of_var],\n",
    "        \"Accuracy\": [Accuracy],\n",
    "        # \"Precision\": [Precision],\n",
    "        \"Recall\": [Recall],\n",
    "        \"F1\": [F1],\n",
    "        \"Error rate\": [MyScore2], # 1 - Accuracy （全要素中、何割間違えたか）\n",
    "        \"1/(1+FP+FN)\": [MyScore],\n",
    "        \"Time\": [tim],\n",
    "        # \"DTW\": DTW_dict_list,\n",
    "        # \"DTW_mean\": DTW_mean_list,\n",
    "        # \"Coeff_result\": [np.concatenate([B0_pred,B1_pred])],\n",
    "        # \"Coeff_result_std\": Coeff_result_std_list,\n",
    "        \"Coeff_Truth\": [coeff_truth],\n",
    "        \"Coeff_result_probability\": [coeff_pred]\n",
    "    })\n",
    "    df.to_csv(\"Results_MMHC_\"+str(num_of_var)+\".csv\", sep=\",\", encoding=\"utf-8\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8406f0-f366-4b00-9828-2e4af1d4c085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae37035c-5bf6-48aa-962f-d63d51e56145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A  B  C  D  E  F  G  H\n",
       "0     0  2  0  0  1  2  0  2\n",
       "1     0  2  0  1  1  1  0  2\n",
       "2     2  0  2  0  0  0  1  1\n",
       "3     0  0  2  1  0  2  2  1\n",
       "4     1  1  0  1  2  1  1  1\n",
       "...  .. .. .. .. .. .. .. ..\n",
       "2495  0  0  1  2  2  0  0  0\n",
       "2496  0  2  1  1  1  0  0  0\n",
       "2497  0  2  1  1  2  1  0  0\n",
       "2498  0  1  1  2  1  0  2  1\n",
       "2499  1  1  1  1  0  1  1  0\n",
       "\n",
       "[2500 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(np.random.randint(0, 3, size=(2500, 8)), columns=list('ABCDEFGH'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
